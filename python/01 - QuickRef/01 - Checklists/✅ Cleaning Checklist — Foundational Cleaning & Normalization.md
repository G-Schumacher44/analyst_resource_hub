___
## ğŸ¯ Purpose

Use this checklist to verify that a dataset is structurally clean, minimally transformed, and ready for exploratory analysis or early-stage modeling.

---

## ğŸ“¦ Structural Review

* [ ] Columns match expected schema or dictionary
* [ ] Row and column count is as expected
* [ ] Column names are standardized (no hidden whitespace or case mismatch)

---

## ğŸ”¢ Data Type Enforcement

* [ ] All numeric fields are numeric (`int`, `float`)
* [ ] Datetime fields parsed and coerced to datetime type
* [ ] Boolean flags cast from string/object to `bool`
* [ ] Object columns reviewed for misclassification (e.g. encoded numerics)

---

## ğŸ§¹ Value Normalization

* [ ] String fields cleaned (whitespace, case, symbols)
* [ ] Currency / % fields converted to numeric
* [ ] Placeholder error values handled (e.g. `-999`, `N/A`, `'missing'`)

---

## â“ Missing Data Handling

* [ ] Missing value summary created and reviewed
* [ ] Light imputation applied (mean, median, mode, constant)
* [ ] Optional: imputed values flagged (`*_imputed`)

---

## ğŸ“ Outlier Detection

* [ ] Z-score or IQR flags created for numeric features
* [ ] Outliers noted or flagged but not removed unless justified

---

## ğŸ“¦ Categorical Handling

* [ ] High-cardinality variables reviewed
* [ ] Rare levels grouped (e.g. â€œOtherâ€ if <1â€“5%)
* [ ] Text categories standardized (case, whitespace, punctuation)

---

## ğŸ’¾ Dataset Savepoint

* [ ] Cleaned dataset exported or saved as new version
* [ ] Notes taken on changes from original
* [ ] Prepared for use in EDA, transformation, or modeling steps

---

## ğŸ§  Final Tip

> â€œFoundational cleaning gets the dataset aligned and safe to explore â€” without breaking assumptions or burying problems.â€
